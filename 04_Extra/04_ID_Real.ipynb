{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocesado y dividido:\n",
      "- Entrenamiento: 1062 im谩genes\n",
      "- Validaci贸n: 132 im谩genes\n",
      "- Prueba: 134 im谩genes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Directorio donde est谩n las im谩genes organizadas por carpetas (una por cada set)\n",
    "data_dir = \"../TRABAJO/FOTOS\"\n",
    "\n",
    "# Transformaciones para las im谩genes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar todas las im谩genes\n",
    "    transforms.RandomHorizontalFlip(),  # Aumento de datos: reflejo horizontal\n",
    "    transforms.RandomRotation(15),  # Aumento de datos: rotaci贸n aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Ajuste de color\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalizar valores de p铆xeles\n",
    "])\n",
    "\n",
    "# Cargar dataset con ImageFolder (cada carpeta es una clase)\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Dividir en entrenamiento (80%), validaci贸n (10%) y prueba (10%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Dataset preprocesado y dividido:\")\n",
    "print(f\"- Entrenamiento: {len(train_dataset)} im谩genes\")\n",
    "print(f\"- Validaci贸n: {len(val_dataset)} im谩genes\")\n",
    "print(f\"- Prueba: {len(test_dataset)} im谩genes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/luismgl/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|| 20.5M/20.5M [00:32<00:00, 669kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poca 1/20 - P茅rdida: 3.0010 - Acc. Entrenamiento: 29.94% - Acc. Validaci贸n: 61.36%\n",
      "poca 2/20 - P茅rdida: 1.1246 - Acc. Entrenamiento: 73.35% - Acc. Validaci贸n: 69.70%\n",
      "poca 3/20 - P茅rdida: 0.5109 - Acc. Entrenamiento: 87.76% - Acc. Validaci贸n: 80.30%\n",
      "poca 4/20 - P茅rdida: 0.3732 - Acc. Entrenamiento: 90.77% - Acc. Validaci贸n: 76.52%\n",
      "poca 5/20 - P茅rdida: 0.2413 - Acc. Entrenamiento: 94.54% - Acc. Validaci贸n: 81.06%\n",
      "poca 6/20 - P茅rdida: 0.2301 - Acc. Entrenamiento: 94.16% - Acc. Validaci贸n: 81.06%\n",
      "poca 7/20 - P茅rdida: 0.1565 - Acc. Entrenamiento: 96.05% - Acc. Validaci贸n: 81.06%\n",
      "poca 8/20 - P茅rdida: 0.0919 - Acc. Entrenamiento: 98.31% - Acc. Validaci贸n: 81.06%\n",
      "poca 9/20 - P茅rdida: 0.0751 - Acc. Entrenamiento: 98.40% - Acc. Validaci贸n: 84.85%\n",
      "poca 10/20 - P茅rdida: 0.0764 - Acc. Entrenamiento: 98.21% - Acc. Validaci贸n: 82.58%\n",
      "poca 11/20 - P茅rdida: 0.1471 - Acc. Entrenamiento: 96.42% - Acc. Validaci贸n: 78.79%\n",
      "poca 12/20 - P茅rdida: 0.1310 - Acc. Entrenamiento: 97.27% - Acc. Validaci贸n: 80.30%\n",
      "poca 13/20 - P茅rdida: 0.1711 - Acc. Entrenamiento: 94.73% - Acc. Validaci贸n: 80.30%\n",
      "poca 14/20 - P茅rdida: 0.1798 - Acc. Entrenamiento: 95.57% - Acc. Validaci贸n: 77.27%\n",
      "poca 15/20 - P茅rdida: 0.2588 - Acc. Entrenamiento: 94.16% - Acc. Validaci贸n: 81.06%\n",
      "poca 16/20 - P茅rdida: 0.1818 - Acc. Entrenamiento: 95.20% - Acc. Validaci贸n: 77.27%\n",
      "poca 17/20 - P茅rdida: 0.0797 - Acc. Entrenamiento: 97.93% - Acc. Validaci贸n: 81.06%\n",
      "poca 18/20 - P茅rdida: 0.0555 - Acc. Entrenamiento: 98.78% - Acc. Validaci贸n: 79.55%\n",
      "poca 19/20 - P茅rdida: 0.0594 - Acc. Entrenamiento: 99.06% - Acc. Validaci贸n: 83.33%\n",
      "poca 20/20 - P茅rdida: 0.0581 - Acc. Entrenamiento: 98.78% - Acc. Validaci贸n: 79.55%\n",
      "Entrenamiento finalizado. Modelo guardado.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Comprobar si hay GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el modelo preentrenado EfficientNetB0\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modificar la 煤ltima capa para clasificar nuestros sets de LEGO\n",
    "num_features = model.classifier[1].in_features\n",
    "num_classes = len(dataset.classes)  # N煤mero de sets de LEGO\n",
    "model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Enviar el modelo a GPU si est谩 disponible\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir la funci贸n de p茅rdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct / total\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    # Evaluaci贸n en conjunto de validaci贸n\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"poca {epoch+1}/{num_epochs} - P茅rdida: {running_loss/len(train_loader):.4f} - \"\n",
    "          f\"Acc. Entrenamiento: {train_acc:.2f}% - Acc. Validaci贸n: {val_acc:.2f}%\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), \"../04_Extra/ID/modelo_lego.pth\")\n",
    "print(\"Entrenamiento finalizado. Modelo guardado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "- Im谩genes de entrenamiento: 1062\n",
      "- Im谩genes de validaci贸n: 132\n",
      "- Im谩genes de prueba: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poca 1/30 - P茅rdida: 3.3045 - Acc. Entrenamiento: 19.96% - Acc. Validaci贸n: 44.70% - P茅rdida Validaci贸n: 2.4201\n",
      "poca 2/30 - P茅rdida: 1.6719 - Acc. Entrenamiento: 59.51% - Acc. Validaci贸n: 70.45% - P茅rdida Validaci贸n: 1.3222\n",
      "poca 3/30 - P茅rdida: 0.8783 - Acc. Entrenamiento: 78.34% - Acc. Validaci贸n: 74.24% - P茅rdida Validaci贸n: 1.0850\n",
      "poca 4/30 - P茅rdida: 0.5218 - Acc. Entrenamiento: 86.06% - Acc. Validaci贸n: 78.03% - P茅rdida Validaci贸n: 1.0551\n",
      "poca 5/30 - P茅rdida: 0.3416 - Acc. Entrenamiento: 91.71% - Acc. Validaci贸n: 80.30% - P茅rdida Validaci贸n: 0.9184\n",
      "poca 6/30 - P茅rdida: 0.3638 - Acc. Entrenamiento: 90.30% - Acc. Validaci贸n: 72.73% - P茅rdida Validaci贸n: 1.1852\n",
      "poca 7/30 - P茅rdida: 0.3345 - Acc. Entrenamiento: 91.34% - Acc. Validaci贸n: 75.76% - P茅rdida Validaci贸n: 1.1977\n",
      "poca 8/30 - P茅rdida: 0.2484 - Acc. Entrenamiento: 93.79% - Acc. Validaci贸n: 81.82% - P茅rdida Validaci贸n: 0.8905\n",
      "poca 9/30 - P茅rdida: 0.2322 - Acc. Entrenamiento: 93.50% - Acc. Validaci贸n: 78.03% - P茅rdida Validaci贸n: 1.1362\n",
      "poca 10/30 - P茅rdida: 0.1795 - Acc. Entrenamiento: 95.01% - Acc. Validaci贸n: 81.06% - P茅rdida Validaci贸n: 1.2961\n",
      "poca 11/30 - P茅rdida: 0.1600 - Acc. Entrenamiento: 96.42% - Acc. Validaci贸n: 80.30% - P茅rdida Validaci贸n: 1.4190\n",
      "poca 12/30 - P茅rdida: 0.2073 - Acc. Entrenamiento: 94.44% - Acc. Validaci贸n: 82.58% - P茅rdida Validaci贸n: 1.1449\n",
      "Early stopping activado en la 茅poca 13\n",
      "Entrenamiento finalizado. Modelo guardado como 'modelo_lego_final.pth'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "# Comprobar si hay GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Directorio del dataset\n",
    "data_dir = \"../TRABAJO/FOTOS\"\n",
    "\n",
    "# Aumento de datos y preprocesamiento\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar im谩genes\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Reflejo horizontal aleatorio\n",
    "    transforms.RandomRotation(15),  # Rotaci贸n aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variaci贸n de color\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),  # Peque帽os desplazamientos\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Perspectiva aleatoria\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalizaci贸n\n",
    "])\n",
    "\n",
    "# Cargar dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)  # N煤mero de sets de LEGO\n",
    "\n",
    "# Dividir en entrenamiento (80%), validaci贸n (10%) y prueba (10%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"- Im谩genes de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"- Im谩genes de validaci贸n: {len(val_dataset)}\")\n",
    "print(f\"- Im谩genes de prueba: {len(test_dataset)}\")\n",
    "\n",
    "# Cargar modelo preentrenado EfficientNetB0\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modificar la 煤ltima capa para clasificar nuestros sets de LEGO\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),  # Dropout para evitar sobreajuste\n",
    "    nn.Linear(num_features, num_classes)\n",
    ")\n",
    "\n",
    "# Enviar modelo a GPU si est谩 disponible\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir funci贸n de p茅rdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Scheduler para reducir el LR si la validaci贸n no mejora\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# Early Stopping manual\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = np.inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Evaluaci贸n en validaci贸n\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Reducir el LR si la validaci贸n no mejora\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"../04_Extra/ID/modelo_lego_final.pth\")  # Guardar el mejor modelo\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"Early stopping activado en la 茅poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"poca {epoch+1}/{num_epochs} - \"\n",
    "          f\"P茅rdida: {avg_train_loss:.4f} - Acc. Entrenamiento: {train_acc:.2f}% - \"\n",
    "          f\"Acc. Validaci贸n: {val_acc:.2f}% - P茅rdida Validaci贸n: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"Entrenamiento finalizado. Modelo guardado como 'modelo_lego_final.pth'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "- Im谩genes de entrenamiento: 1062\n",
      "- Im谩genes de validaci贸n: 132\n",
      "- Im谩genes de prueba: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poca 1/30 - P茅rdida Entrenamiento: 3.9686 - Acc. Entrenamiento: 4.14% - P茅rdida Validaci贸n: 3.8552 - Acc. Validaci贸n: 5.30%\n",
      "poca 2/30 - P茅rdida Entrenamiento: 3.6987 - Acc. Entrenamiento: 6.87% - P茅rdida Validaci贸n: 3.6807 - Acc. Validaci贸n: 12.12%\n",
      "poca 3/30 - P茅rdida Entrenamiento: 3.5373 - Acc. Entrenamiento: 12.99% - P茅rdida Validaci贸n: 3.4246 - Acc. Validaci贸n: 14.39%\n",
      "poca 4/30 - P茅rdida Entrenamiento: 3.3987 - Acc. Entrenamiento: 16.38% - P茅rdida Validaci贸n: 3.3707 - Acc. Validaci贸n: 17.42%\n",
      "poca 5/30 - P茅rdida Entrenamiento: 3.2620 - Acc. Entrenamiento: 16.67% - P茅rdida Validaci贸n: 3.3021 - Acc. Validaci贸n: 19.70%\n",
      " Descongelando capas base...\n",
      "poca 6/30 - P茅rdida Entrenamiento: 3.1297 - Acc. Entrenamiento: 20.34% - P茅rdida Validaci贸n: 3.2396 - Acc. Validaci贸n: 23.48%\n",
      "poca 7/30 - P茅rdida Entrenamiento: 3.0409 - Acc. Entrenamiento: 25.05% - P茅rdida Validaci贸n: 3.0874 - Acc. Validaci贸n: 25.00%\n",
      "poca 8/30 - P茅rdida Entrenamiento: 2.8796 - Acc. Entrenamiento: 26.46% - P茅rdida Validaci贸n: 3.0883 - Acc. Validaci贸n: 24.24%\n",
      "poca 9/30 - P茅rdida Entrenamiento: 2.7547 - Acc. Entrenamiento: 30.51% - P茅rdida Validaci贸n: 2.8883 - Acc. Validaci贸n: 28.03%\n",
      "poca 10/30 - P茅rdida Entrenamiento: 2.6363 - Acc. Entrenamiento: 34.46% - P茅rdida Validaci贸n: 2.8910 - Acc. Validaci贸n: 28.03%\n",
      "poca 11/30 - P茅rdida Entrenamiento: 2.5441 - Acc. Entrenamiento: 35.97% - P茅rdida Validaci贸n: 2.7850 - Acc. Validaci贸n: 28.79%\n",
      "poca 12/30 - P茅rdida Entrenamiento: 2.5071 - Acc. Entrenamiento: 33.71% - P茅rdida Validaci贸n: 2.6134 - Acc. Validaci贸n: 33.33%\n",
      "poca 13/30 - P茅rdida Entrenamiento: 2.3923 - Acc. Entrenamiento: 38.14% - P茅rdida Validaci贸n: 2.7089 - Acc. Validaci贸n: 37.88%\n",
      "poca 14/30 - P茅rdida Entrenamiento: 2.3151 - Acc. Entrenamiento: 41.90% - P茅rdida Validaci贸n: 2.6099 - Acc. Validaci贸n: 37.12%\n",
      "poca 15/30 - P茅rdida Entrenamiento: 2.2388 - Acc. Entrenamiento: 44.16% - P茅rdida Validaci贸n: 2.4158 - Acc. Validaci贸n: 42.42%\n",
      "poca 16/30 - P茅rdida Entrenamiento: 2.1105 - Acc. Entrenamiento: 48.40% - P茅rdida Validaci贸n: 2.3778 - Acc. Validaci贸n: 40.91%\n",
      "poca 17/30 - P茅rdida Entrenamiento: 2.0557 - Acc. Entrenamiento: 46.80% - P茅rdida Validaci贸n: 2.2944 - Acc. Validaci贸n: 47.73%\n",
      "poca 18/30 - P茅rdida Entrenamiento: 1.9891 - Acc. Entrenamiento: 48.21% - P茅rdida Validaci贸n: 2.2313 - Acc. Validaci贸n: 41.67%\n",
      "poca 19/30 - P茅rdida Entrenamiento: 1.9820 - Acc. Entrenamiento: 48.31% - P茅rdida Validaci贸n: 2.0173 - Acc. Validaci贸n: 47.73%\n",
      "poca 20/30 - P茅rdida Entrenamiento: 1.8669 - Acc. Entrenamiento: 51.98% - P茅rdida Validaci贸n: 2.1220 - Acc. Validaci贸n: 47.73%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "#  Elegir modelo (EfficientNetB0 o ResNet50)\n",
    "MODEL_NAME = \"efficientnet\"\n",
    "\n",
    "#  Configuraci贸n del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "#  Directorio del dataset\n",
    "data_dir = \"../TRABAJO/FOTOS\"\n",
    "\n",
    "#  Data Augmentation Mejorado\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),  # Variabilidad de tama帽o\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.4),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.4),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Desenfoque aleatorio\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.456], [0.406])\n",
    "])\n",
    "\n",
    "#  Cargar dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "#  Divisi贸n en entrenamiento (80%), validaci贸n (10%) y prueba (10%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#  Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"- Im谩genes de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"- Im谩genes de validaci贸n: {len(val_dataset)}\")\n",
    "print(f\"- Im谩genes de prueba: {len(test_dataset)}\")\n",
    "\n",
    "#  Cargar modelo seleccionado\n",
    "if MODEL_NAME == \"efficientnet\":\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "    num_features = model.classifier[1].in_features\n",
    "\n",
    "    #  Transfer Learning: Congelar capas base las primeras 5 茅pocas\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.6),\n",
    "        nn.Linear(num_features, num_classes)\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#  Optimizer y Learning Rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "#  Funci贸n de p茅rdida y reducci贸n del LR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=2, verbose=True)\n",
    "\n",
    "early_stopping_patience = 4\n",
    "best_val_loss = np.inf\n",
    "epochs_no_improve = 0\n",
    "unfreeze_epoch = 5  # Descongelar capas base despu茅s de 5 茅pocas\n",
    "\n",
    "#  Entrenamiento del modelo\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    #  Descongelar capas base despu茅s de 5 茅pocas\n",
    "    if epoch == unfreeze_epoch:\n",
    "        print(\" Descongelando capas base...\")\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)  # Reducir LR\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    #  Evaluaci贸n en validaci贸n\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    #  Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"../04_Extra/ID/modelo_lego_final.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\" Early stopping activado en la 茅poca {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"poca {epoch+1}/{num_epochs} - \"\n",
    "          f\"P茅rdida Entrenamiento: {avg_train_loss:.4f} - Acc. Entrenamiento: {train_acc:.2f}% - \"\n",
    "          f\"P茅rdida Validaci贸n: {avg_val_loss:.4f} - Acc. Validaci贸n: {val_acc:.2f}%\")\n",
    "\n",
    "print(\" Entrenamiento finalizado. Modelo guardado como 'modelo_lego_final.pth'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
