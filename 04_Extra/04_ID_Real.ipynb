{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocesado y dividido:\n",
      "- Entrenamiento: 1062 imágenes\n",
      "- Validación: 132 imágenes\n",
      "- Prueba: 134 imágenes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Directorio donde están las imágenes organizadas por carpetas (una por cada set)\n",
    "data_dir = \"../TRABAJO/FOTOS\"\n",
    "\n",
    "# Transformaciones para las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar todas las imágenes\n",
    "    transforms.RandomHorizontalFlip(),  # Aumento de datos: reflejo horizontal\n",
    "    transforms.RandomRotation(15),  # Aumento de datos: rotación aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Ajuste de color\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalizar valores de píxeles\n",
    "])\n",
    "\n",
    "# Cargar dataset con ImageFolder (cada carpeta es una clase)\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Dividir en entrenamiento (80%), validación (10%) y prueba (10%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Dataset preprocesado y dividido:\")\n",
    "print(f\"- Entrenamiento: {len(train_dataset)} imágenes\")\n",
    "print(f\"- Validación: {len(val_dataset)} imágenes\")\n",
    "print(f\"- Prueba: {len(test_dataset)} imágenes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/luismgl/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:32<00:00, 669kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/20 - Pérdida: 3.0010 - Acc. Entrenamiento: 29.94% - Acc. Validación: 61.36%\n",
      "Época 2/20 - Pérdida: 1.1246 - Acc. Entrenamiento: 73.35% - Acc. Validación: 69.70%\n",
      "Época 3/20 - Pérdida: 0.5109 - Acc. Entrenamiento: 87.76% - Acc. Validación: 80.30%\n",
      "Época 4/20 - Pérdida: 0.3732 - Acc. Entrenamiento: 90.77% - Acc. Validación: 76.52%\n",
      "Época 5/20 - Pérdida: 0.2413 - Acc. Entrenamiento: 94.54% - Acc. Validación: 81.06%\n",
      "Época 6/20 - Pérdida: 0.2301 - Acc. Entrenamiento: 94.16% - Acc. Validación: 81.06%\n",
      "Época 7/20 - Pérdida: 0.1565 - Acc. Entrenamiento: 96.05% - Acc. Validación: 81.06%\n",
      "Época 8/20 - Pérdida: 0.0919 - Acc. Entrenamiento: 98.31% - Acc. Validación: 81.06%\n",
      "Época 9/20 - Pérdida: 0.0751 - Acc. Entrenamiento: 98.40% - Acc. Validación: 84.85%\n",
      "Época 10/20 - Pérdida: 0.0764 - Acc. Entrenamiento: 98.21% - Acc. Validación: 82.58%\n",
      "Época 11/20 - Pérdida: 0.1471 - Acc. Entrenamiento: 96.42% - Acc. Validación: 78.79%\n",
      "Época 12/20 - Pérdida: 0.1310 - Acc. Entrenamiento: 97.27% - Acc. Validación: 80.30%\n",
      "Época 13/20 - Pérdida: 0.1711 - Acc. Entrenamiento: 94.73% - Acc. Validación: 80.30%\n",
      "Época 14/20 - Pérdida: 0.1798 - Acc. Entrenamiento: 95.57% - Acc. Validación: 77.27%\n",
      "Época 15/20 - Pérdida: 0.2588 - Acc. Entrenamiento: 94.16% - Acc. Validación: 81.06%\n",
      "Época 16/20 - Pérdida: 0.1818 - Acc. Entrenamiento: 95.20% - Acc. Validación: 77.27%\n",
      "Época 17/20 - Pérdida: 0.0797 - Acc. Entrenamiento: 97.93% - Acc. Validación: 81.06%\n",
      "Época 18/20 - Pérdida: 0.0555 - Acc. Entrenamiento: 98.78% - Acc. Validación: 79.55%\n",
      "Época 19/20 - Pérdida: 0.0594 - Acc. Entrenamiento: 99.06% - Acc. Validación: 83.33%\n",
      "Época 20/20 - Pérdida: 0.0581 - Acc. Entrenamiento: 98.78% - Acc. Validación: 79.55%\n",
      "Entrenamiento finalizado. Modelo guardado.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Comprobar si hay GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar el modelo preentrenado EfficientNetB0\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modificar la última capa para clasificar nuestros sets de LEGO\n",
    "num_features = model.classifier[1].in_features\n",
    "num_classes = len(dataset.classes)  # Número de sets de LEGO\n",
    "model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Enviar el modelo a GPU si está disponible\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct / total\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    # Evaluación en conjunto de validación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - Pérdida: {running_loss/len(train_loader):.4f} - \"\n",
    "          f\"Acc. Entrenamiento: {train_acc:.2f}% - Acc. Validación: {val_acc:.2f}%\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), \"../04_Extra/ID/modelo_lego.pth\")\n",
    "print(\"Entrenamiento finalizado. Modelo guardado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "- Imágenes de entrenamiento: 1062\n",
      "- Imágenes de validación: 132\n",
      "- Imágenes de prueba: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/30 - Pérdida: 3.3045 - Acc. Entrenamiento: 19.96% - Acc. Validación: 44.70% - Pérdida Validación: 2.4201\n",
      "Época 2/30 - Pérdida: 1.6719 - Acc. Entrenamiento: 59.51% - Acc. Validación: 70.45% - Pérdida Validación: 1.3222\n",
      "Época 3/30 - Pérdida: 0.8783 - Acc. Entrenamiento: 78.34% - Acc. Validación: 74.24% - Pérdida Validación: 1.0850\n",
      "Época 4/30 - Pérdida: 0.5218 - Acc. Entrenamiento: 86.06% - Acc. Validación: 78.03% - Pérdida Validación: 1.0551\n",
      "Época 5/30 - Pérdida: 0.3416 - Acc. Entrenamiento: 91.71% - Acc. Validación: 80.30% - Pérdida Validación: 0.9184\n",
      "Época 6/30 - Pérdida: 0.3638 - Acc. Entrenamiento: 90.30% - Acc. Validación: 72.73% - Pérdida Validación: 1.1852\n",
      "Época 7/30 - Pérdida: 0.3345 - Acc. Entrenamiento: 91.34% - Acc. Validación: 75.76% - Pérdida Validación: 1.1977\n",
      "Época 8/30 - Pérdida: 0.2484 - Acc. Entrenamiento: 93.79% - Acc. Validación: 81.82% - Pérdida Validación: 0.8905\n",
      "Época 9/30 - Pérdida: 0.2322 - Acc. Entrenamiento: 93.50% - Acc. Validación: 78.03% - Pérdida Validación: 1.1362\n",
      "Época 10/30 - Pérdida: 0.1795 - Acc. Entrenamiento: 95.01% - Acc. Validación: 81.06% - Pérdida Validación: 1.2961\n",
      "Época 11/30 - Pérdida: 0.1600 - Acc. Entrenamiento: 96.42% - Acc. Validación: 80.30% - Pérdida Validación: 1.4190\n",
      "Época 12/30 - Pérdida: 0.2073 - Acc. Entrenamiento: 94.44% - Acc. Validación: 82.58% - Pérdida Validación: 1.1449\n",
      "Early stopping activado en la época 13\n",
      "Entrenamiento finalizado. Modelo guardado como 'modelo_lego_final.pth'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "# Comprobar si hay GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Directorio del dataset\n",
    "data_dir = \"../TRABAJO/FOTOS\"\n",
    "\n",
    "# Aumento de datos y preprocesamiento\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar imágenes\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Reflejo horizontal aleatorio\n",
    "    transforms.RandomRotation(15),  # Rotación aleatoria\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variación de color\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),  # Pequeños desplazamientos\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Perspectiva aleatoria\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalización\n",
    "])\n",
    "\n",
    "# Cargar dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)  # Número de sets de LEGO\n",
    "\n",
    "# Dividir en entrenamiento (80%), validación (10%) y prueba (10%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"- Imágenes de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"- Imágenes de validación: {len(val_dataset)}\")\n",
    "print(f\"- Imágenes de prueba: {len(test_dataset)}\")\n",
    "\n",
    "# Cargar modelo preentrenado EfficientNetB0\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modificar la última capa para clasificar nuestros sets de LEGO\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),  # Dropout para evitar sobreajuste\n",
    "    nn.Linear(num_features, num_classes)\n",
    ")\n",
    "\n",
    "# Enviar modelo a GPU si está disponible\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Scheduler para reducir el LR si la validación no mejora\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# Early Stopping manual\n",
    "early_stopping_patience = 5\n",
    "best_val_loss = np.inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Evaluación en validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Reducir el LR si la validación no mejora\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"../04_Extra/ID/modelo_lego_final.pth\")  # Guardar el mejor modelo\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"Early stopping activado en la época {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - \"\n",
    "          f\"Pérdida: {avg_train_loss:.4f} - Acc. Entrenamiento: {train_acc:.2f}% - \"\n",
    "          f\"Acc. Validación: {val_acc:.2f}% - Pérdida Validación: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(\"Entrenamiento finalizado. Modelo guardado como 'modelo_lego_final.pth'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "- Imágenes de entrenamiento: 1062\n",
      "- Imágenes de validación: 132\n",
      "- Imágenes de prueba: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/luismgl/Library/Python/3.9/lib/python/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/30 - Pérdida Entrenamiento: 3.9686 - Acc. Entrenamiento: 4.14% - Pérdida Validación: 3.8552 - Acc. Validación: 5.30%\n",
      "Época 2/30 - Pérdida Entrenamiento: 3.6987 - Acc. Entrenamiento: 6.87% - Pérdida Validación: 3.6807 - Acc. Validación: 12.12%\n",
      "Época 3/30 - Pérdida Entrenamiento: 3.5373 - Acc. Entrenamiento: 12.99% - Pérdida Validación: 3.4246 - Acc. Validación: 14.39%\n",
      "Época 4/30 - Pérdida Entrenamiento: 3.3987 - Acc. Entrenamiento: 16.38% - Pérdida Validación: 3.3707 - Acc. Validación: 17.42%\n",
      "Época 5/30 - Pérdida Entrenamiento: 3.2620 - Acc. Entrenamiento: 16.67% - Pérdida Validación: 3.3021 - Acc. Validación: 19.70%\n",
      "🔓 Descongelando capas base...\n",
      "Época 6/30 - Pérdida Entrenamiento: 3.1297 - Acc. Entrenamiento: 20.34% - Pérdida Validación: 3.2396 - Acc. Validación: 23.48%\n",
      "Época 7/30 - Pérdida Entrenamiento: 3.0409 - Acc. Entrenamiento: 25.05% - Pérdida Validación: 3.0874 - Acc. Validación: 25.00%\n",
      "Época 8/30 - Pérdida Entrenamiento: 2.8796 - Acc. Entrenamiento: 26.46% - Pérdida Validación: 3.0883 - Acc. Validación: 24.24%\n",
      "Época 9/30 - Pérdida Entrenamiento: 2.7547 - Acc. Entrenamiento: 30.51% - Pérdida Validación: 2.8883 - Acc. Validación: 28.03%\n",
      "Época 10/30 - Pérdida Entrenamiento: 2.6363 - Acc. Entrenamiento: 34.46% - Pérdida Validación: 2.8910 - Acc. Validación: 28.03%\n",
      "Época 11/30 - Pérdida Entrenamiento: 2.5441 - Acc. Entrenamiento: 35.97% - Pérdida Validación: 2.7850 - Acc. Validación: 28.79%\n",
      "Época 12/30 - Pérdida Entrenamiento: 2.5071 - Acc. Entrenamiento: 33.71% - Pérdida Validación: 2.6134 - Acc. Validación: 33.33%\n",
      "Época 13/30 - Pérdida Entrenamiento: 2.3923 - Acc. Entrenamiento: 38.14% - Pérdida Validación: 2.7089 - Acc. Validación: 37.88%\n",
      "Época 14/30 - Pérdida Entrenamiento: 2.3151 - Acc. Entrenamiento: 41.90% - Pérdida Validación: 2.6099 - Acc. Validación: 37.12%\n",
      "Época 15/30 - Pérdida Entrenamiento: 2.2388 - Acc. Entrenamiento: 44.16% - Pérdida Validación: 2.4158 - Acc. Validación: 42.42%\n",
      "Época 16/30 - Pérdida Entrenamiento: 2.1105 - Acc. Entrenamiento: 48.40% - Pérdida Validación: 2.3778 - Acc. Validación: 40.91%\n",
      "Época 17/30 - Pérdida Entrenamiento: 2.0557 - Acc. Entrenamiento: 46.80% - Pérdida Validación: 2.2944 - Acc. Validación: 47.73%\n",
      "Época 18/30 - Pérdida Entrenamiento: 1.9891 - Acc. Entrenamiento: 48.21% - Pérdida Validación: 2.2313 - Acc. Validación: 41.67%\n",
      "Época 19/30 - Pérdida Entrenamiento: 1.9820 - Acc. Entrenamiento: 48.31% - Pérdida Validación: 2.0173 - Acc. Validación: 47.73%\n",
      "Época 20/30 - Pérdida Entrenamiento: 1.8669 - Acc. Entrenamiento: 51.98% - Pérdida Validación: 2.1220 - Acc. Validación: 47.73%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "# 🚀 Elegir modelo (EfficientNetB0 o ResNet50)\n",
    "MODEL_NAME = \"efficientnet\"\n",
    "\n",
    "# 🔥 Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# 🔥 Directorio del dataset\n",
    "data_dir = \"../TRABAJO/FOTOS\"\n",
    "\n",
    "# 🔥 Data Augmentation Mejorado\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),  # Variabilidad de tamaño\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.4),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.2, 0.2)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.RandomGrayscale(p=0.4),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Desenfoque aleatorio\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.456], [0.406])\n",
    "])\n",
    "\n",
    "# 🔥 Cargar dataset\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "# 🔥 División en entrenamiento (80%), validación (10%) y prueba (10%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 🔥 Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"- Imágenes de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"- Imágenes de validación: {len(val_dataset)}\")\n",
    "print(f\"- Imágenes de prueba: {len(test_dataset)}\")\n",
    "\n",
    "# 🔥 Cargar modelo seleccionado\n",
    "if MODEL_NAME == \"efficientnet\":\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "    num_features = model.classifier[1].in_features\n",
    "\n",
    "    # 🔥 Transfer Learning: Congelar capas base las primeras 5 épocas\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.6),\n",
    "        nn.Linear(num_features, num_classes)\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 🔥 Optimizer y Learning Rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# 🔥 Función de pérdida y reducción del LR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=2, verbose=True)\n",
    "\n",
    "early_stopping_patience = 4\n",
    "best_val_loss = np.inf\n",
    "epochs_no_improve = 0\n",
    "unfreeze_epoch = 5  # Descongelar capas base después de 5 épocas\n",
    "\n",
    "# 🚀 Entrenamiento del modelo\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # 🔥 Descongelar capas base después de 5 épocas\n",
    "    if epoch == unfreeze_epoch:\n",
    "        print(\"🔓 Descongelando capas base...\")\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)  # Reducir LR\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # 🔥 Evaluación en validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct_val / total_val\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # 🔥 Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"../04_Extra/ID/modelo_lego_final.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"🚨 Early stopping activado en la época {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Época {epoch+1}/{num_epochs} - \"\n",
    "          f\"Pérdida Entrenamiento: {avg_train_loss:.4f} - Acc. Entrenamiento: {train_acc:.2f}% - \"\n",
    "          f\"Pérdida Validación: {avg_val_loss:.4f} - Acc. Validación: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"🎉 Entrenamiento finalizado. Modelo guardado como 'modelo_lego_final.pth'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
