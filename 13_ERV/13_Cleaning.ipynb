{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar variables de entorno desde .env\n",
    "load_dotenv()\n",
    "\n",
    "def procesar_y_guardar_lego(csv_file, db_name=\"dbo_lego\", collection_name=\"lego_work\"):\n",
    "    \"\"\"\n",
    "    Carga un CSV de sets de LEGO, filtra los datos seg煤n los temas seleccionados y\n",
    "    los guarda en una base de datos MongoDB.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtener mongo_uri desde .env\n",
    "    mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "\n",
    "    if not mongo_uri:\n",
    "        raise ValueError(\"La variable MONGO_URI no est谩 definida en el archivo .env\")\n",
    "\n",
    "    # Cargar CSV\n",
    "    df_lego_inicial = pd.read_csv(csv_file)\n",
    "\n",
    "    # Lista de temas elegidos\n",
    "    selected_themes = [\n",
    "    \"Speed Champions\", \"Architecture\", \"BrickHeadz\", \"Star Wars\", \"Ideas\", \"Collectable Minifigures\",\n",
    "    \"Technic\", \"Minecraft\", \"Harry Potter\", \"Icons\", \"Ninjago\", \"Education\", \"Jurassic World\",\n",
    "    \"Duplo\", \"DC Comics Super Heroes\", \"Marvel Super Heroes\", \"Creator\", \"City\", \"Friends\",\n",
    "    \"Classic\", \"Disney\"\n",
    "    ]\n",
    "\n",
    "    # Filtrar dataset\n",
    "    df_lego_work = df_lego_inicial[df_lego_inicial['Theme'].isin(selected_themes)]\n",
    "\n",
    "    # Eliminar columnas innecesarias\n",
    "    columns_to_drop = ['Own', 'Want', 'Unnamed: 49', 'Flag2', 'Flag3', 'Flag4', 'Flag5', 'Flag6', 'Flag7', 'Flag8', 'UserNotes',\n",
    "                       \"Variant\", \"ThemeGroup\", \"EAN\", \"UPC\", \"UKRetailPrice\", 'QtyOwned', 'QtyOwnedNew', 'QtyOwnedUsed',\n",
    "                       'QtyWanted', 'WantedPriority', \"CARetailPrice\", \"DERetailPrice\", \"AdditionalImageCount\", \"InstructionsCount\",\n",
    "                       \"USDateAdded\", \"USDateRemoved\", \"Designers\", \"Image\", \"USItemNumber\", \"EUItemNumber\"]\n",
    "\n",
    "    df_lego_work = df_lego_work.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Conectar a MongoDB\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Convertir el DataFrame a lista de diccionarios e insertarlo en MongoDB\n",
    "    data = df_lego_work.to_dict(orient=\"records\")\n",
    "    if data:\n",
    "        collection.insert_many(data)\n",
    "        print(f\"Datos insertados en MongoDB ({len(data)} registros).\")\n",
    "    else:\n",
    "        print(\"No hay datos para insertar.\")\n",
    "\n",
    "    # Cerrar conexi贸n\n",
    "    client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ema\\AppData\\Local\\Temp\\ipykernel_15668\\1239290459.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_lego_inicial = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos insertados en MongoDB (8481 registros).\n"
     ]
    }
   ],
   "source": [
    "#primera funcion aplicada\n",
    "csv_file = \"Set_Lanzanzados.csv\"\n",
    "procesar_y_guardar_lego(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ema\\AppData\\Local\\Temp\\ipykernel_15668\\362846168.py:15: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_lego['ExitDate'] = pd.to_datetime(df_lego['ExitDate'], errors='coerce')\n",
      "C:\\Users\\Ema\\AppData\\Local\\Temp\\ipykernel_15668\\362846168.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_lego['AnnualPriceIncrease'].fillna(0, inplace=True)\n",
      "C:\\Users\\Ema\\AppData\\Local\\Temp\\ipykernel_15668\\362846168.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_lego['AnnualPercentageIncrease'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos limpiados y guardados en lego_work_final\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def clean_lego_data(df_lego):\n",
    "    df_lego['Subtheme'] = df_lego['Subtheme'].fillna('Unknown')\n",
    "    columns_zero = ['Pieces', 'BrickLinkSoldPriceNew', 'BrickLinkSoldPriceNewUS', 'USRetailPrice',\n",
    "                    'BrickLinkSoldPriceUsed', 'Depth', 'Height', 'Width', 'Weight', 'Minifigs', 'AgeMin', 'AgeMax']\n",
    "    for col in columns_zero:\n",
    "        if col in df_lego.columns:\n",
    "            df_lego[col] = df_lego[col].fillna(0)\n",
    "    df_lego['ImageFilename'] = df_lego['ImageFilename'].fillna('Unknown')\n",
    "    df_lego['LaunchDate'] = pd.to_datetime(df_lego['LaunchDate'], errors='coerce')\n",
    "    df_lego['ExitDate'] = pd.to_datetime(df_lego['ExitDate'], errors='coerce')\n",
    "    df_lego['Duration'] = (df_lego['ExitDate'] - df_lego['LaunchDate']).dt.days / 365.25\n",
    "    theme_median_duration = df_lego.groupby('Theme')['Duration'].median()\n",
    "    for theme, median_duration in theme_median_duration.items():\n",
    "        mask = (df_lego['Theme'] == theme) & df_lego['ExitDate'].isna() & df_lego['LaunchDate'].notna()\n",
    "        df_lego.loc[mask, 'ExitDate'] = df_lego.loc[mask, 'LaunchDate'] + pd.to_timedelta(median_duration * 365.25, unit='D')\n",
    "    mask_launch = df_lego['LaunchDate'].isna() & df_lego['YearFrom'].notna()\n",
    "    df_lego.loc[mask_launch, 'LaunchDate'] = pd.to_datetime(df_lego.loc[mask_launch, 'YearFrom'].astype(int).astype(str) + '-01-01')\n",
    "    df_lego['LaunchYear'] = df_lego['LaunchDate'].dt.year\n",
    "    df_lego['LaunchMonth'] = df_lego['LaunchDate'].dt.month\n",
    "    df_lego['ExitYear'] = df_lego['ExitDate'].dt.year\n",
    "    df_lego['ExitMonth'] = df_lego['ExitDate'].dt.month\n",
    "    df_lego.drop(columns=['LaunchDate', 'ExitDate', 'Duration'], inplace=True)\n",
    "    df_lego['Duration'] = df_lego['ExitYear'] - df_lego['LaunchYear']\n",
    "    theme_avg_duration = df_lego.groupby('Theme')['Duration'].mean()\n",
    "    year_avg_duration = df_lego.groupby('LaunchYear')['Duration'].mean()\n",
    "    for index, row in df_lego.iterrows():\n",
    "        if pd.isna(row['ExitYear']) and not pd.isna(row['LaunchYear']):\n",
    "            estimated_duration = theme_avg_duration.get(row['Theme'], year_avg_duration.get(row['LaunchYear'], None))\n",
    "            if pd.notna(estimated_duration):\n",
    "                df_lego.at[index, 'ExitYear'] = int(row['LaunchYear'] + round(estimated_duration))\n",
    "                df_lego.at[index, 'ExitMonth'] = 12\n",
    "    # Elimino la columna 'Released' y 'Duration' porque no aporta informaci贸n 煤til\n",
    "    df_lego.drop(columns=['Released'], inplace=True)\n",
    "    df_lego.drop(columns=['Duration'], inplace=True)\n",
    "    df_lego['PackagingType'] = df_lego['PackagingType'].replace({\n",
    "        '{Not specified}': 'Unknown', 'Plastic canister': 'Canister', 'Plastic box': 'Box',\n",
    "        'Metal canister': 'Canister', 'Box with handle': 'Box', 'Box with backing card': 'Box',\n",
    "        'None (loose parts)': 'None'})\n",
    "    df_lego['Availability'] = df_lego['Availability'].replace({\n",
    "        '{Not specified}': 'Unknown', 'Promotional (Airline)': 'Promotional'})\n",
    "    df_lego.loc[df_lego['Theme'] == 'Creator Expert', 'Theme'] = 'Icons'\n",
    "    return df_lego\n",
    "\n",
    "def process_lego_data(df_lego):\n",
    "    current_year = datetime.now().year\n",
    "    df_lego['YearsSinceExit'] = (current_year - df_lego['ExitYear']).fillna(0).astype(int)\n",
    "    df_lego['PriceChange'] = ((df_lego['BrickLinkSoldPriceNew'] - df_lego['USRetailPrice']) / df_lego['USRetailPrice']) * 100\n",
    "    df_lego['PriceChange'] = df_lego['PriceChange'].fillna(0)\n",
    "    df_lego['ResaleDemand'] = df_lego.apply(lambda row: row['BrickLinkSoldPriceNew'] / row['BrickLinkSoldPriceUsed']\n",
    "                                             if row['BrickLinkSoldPriceUsed'] > 0 else 0, axis=1)\n",
    "    df_lego['AppreciationTrend'] = df_lego.apply(lambda row: row['PriceChange'] / row['YearsSinceExit']\n",
    "                                                 if row['YearsSinceExit'] > 0 else 0, axis=1)\n",
    "    size_labels = ['Small', 'Medium', 'Large']\n",
    "    df_lego['SizeCategory'] = pd.cut(df_lego['Pieces'], bins=[0, 249, 1000, float('inf')], labels=size_labels, include_lowest=True)\n",
    "    exclusive_themes = ['Star Wars', 'Modular Buildings', 'Ideas', 'Creator Expert', 'Harry Potter',\n",
    "                        'Marvel Super Heroes', 'Ghostbusters', 'Icons', 'The Lord of the Rings',\n",
    "                        'Pirates of the Caribbean', 'Pirates', 'Trains', 'Architecture']\n",
    "    df_lego['Exclusivity'] = df_lego['Theme'].apply(lambda x: 'Exclusive' if x in exclusive_themes else 'Regular')\n",
    "    theme_popularity = df_lego.groupby('Theme')['PriceChange'].mean().replace([np.inf, -np.inf], np.nan)\n",
    "    df_lego['ThemePopularity'] = df_lego['Theme'].map(theme_popularity).fillna(0)\n",
    "    df_lego['InvestmentScore'] = df_lego.apply(lambda row: (row['PriceChange'] * 0.4) +\n",
    "                                                         (row['AppreciationTrend'] * 0.3) +\n",
    "                                                         (row['ThemePopularity'] * 0.2) +\n",
    "                                                         (10 if row['Exclusivity'] == 'Exclusive' else 0), axis=1)\n",
    "\n",
    "    # Calculamos el incremento de precio anual desde que el set fue retirado\n",
    "    df_lego['AnnualPriceIncrease'] = (df_lego['BrickLinkSoldPriceNew'] - df_lego['USRetailPrice']) / df_lego['YearsSinceExit']\n",
    "\n",
    "    # Reemplazamos valores infinitos o NaN (por si hay sets con YearsSinceExit = 0)\n",
    "    df_lego.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_lego['AnnualPriceIncrease'].fillna(0, inplace=True)\n",
    "\n",
    "    # Calculamos el porcentaje de aumento anual del precio desde que el set fue retirado\n",
    "    df_lego['AnnualPercentageIncrease'] = ((df_lego['BrickLinkSoldPriceNew'] - df_lego['USRetailPrice']) /\n",
    "                                       (df_lego['USRetailPrice'] * df_lego['YearsSinceExit'])) * 100\n",
    "\n",
    "    # Reemplazamos valores infinitos o NaN (por si hay YearsSinceExit o USRetailPrice en 0)\n",
    "    df_lego.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_lego['AnnualPercentageIncrease'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return df_lego\n",
    "\n",
    "def main():\n",
    "\n",
    "     # Obtener mongo_uri desde .env\n",
    "    mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "\n",
    "    # Conectar a MongoDB\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client['dbo_lego']  # Reemplaza con el nombre de tu BBDD\n",
    "    collection = db['lego_work']\n",
    "    data = pd.DataFrame(list(collection.find()))\n",
    "    if '_id' in data.columns:\n",
    "        data.drop(columns=['_id'], inplace=True)\n",
    "    data_cleaned = clean_lego_data(data)\n",
    "    data_processed = process_lego_data(data_cleaned)\n",
    "    db['lego_work_final'].insert_many(data_processed.to_dict(orient='records'))\n",
    "    print(\"Datos limpiados y guardados en lego_work_final\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos actualizados en MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def actualizar_lego_en_mongo():\n",
    "    # Leer la URI de MongoDB desde la variable de entorno\n",
    "    mongo_uri = os.getenv(\"MONGO_URI\")\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[\"dbo_lego\"]  # Reemplaza con el nombre correcto de tu BBDD\n",
    "\n",
    "    # Nombre de la colecci贸n original y las de salida\n",
    "    collection_original = \"lego_work_final\"\n",
    "    collection_retirados = \"lego_final_retirados\"\n",
    "    collection_venta = \"lego_final_venta\"\n",
    "\n",
    "    # Leer datos desde MongoDB\n",
    "    data = list(db[collection_original].find())\n",
    "    df_lego_final = pd.DataFrame(data)\n",
    "\n",
    "    # Verificar que la columna ExitYear existe y convertir a num茅rico\n",
    "    df_lego_final['ExitYear'] = pd.to_numeric(df_lego_final.get('ExitYear'), errors='coerce')\n",
    "\n",
    "    # Filtrar los datos seg煤n ExitYear\n",
    "    df_lego_final_retirados = df_lego_final[df_lego_final['ExitYear'] < 2025].copy()\n",
    "    df_lego_final_venta = df_lego_final[df_lego_final['ExitYear'] >= 2025].copy()\n",
    "\n",
    "    # Convertir DataFrames a diccionarios para MongoDB\n",
    "    data_retirados = df_lego_final_retirados.to_dict(orient='records')\n",
    "    data_venta = df_lego_final_venta.to_dict(orient='records')\n",
    "\n",
    "    # Eliminar colecciones si existen y crear nuevas con los datos actualizados\n",
    "    db[collection_retirados].drop()\n",
    "    db[collection_venta].drop()\n",
    "\n",
    "    db[collection_retirados].insert_many(data_retirados) if data_retirados else None\n",
    "    db[collection_venta].insert_many(data_venta) if data_venta else None\n",
    "\n",
    "    print(\"Datos actualizados en MongoDB.\")\n",
    "\n",
    "# Ejecutar la funci贸n si el script se ejecuta directamente\n",
    "if __name__ == \"__main__\":\n",
    "    actualizar_lego_en_mongo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APLICACION ML EN VENTAS, GUARDAR EN MONGODB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ema\\AppData\\Local\\Temp\\ipykernel_15668\\4111964515.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Columnas nuevas agregadas a la colecci贸n: lego_final_venta\n",
      "Datos actualizados correctamente en la colecci贸n: lego_final_venta\n",
      "Columnas nuevas agregadas a la colecci贸n: lego_final_retirados\n",
      "Datos actualizados correctamente en la colecci贸n: lego_final_retirados\n",
      "Ejemplo de documento actualizado en lego_final_venta: {'_id': ObjectId('67c8a69e30a1f61f23a242ab'), 'PredictedInvestmentScore': 89.63012649953507, 'PricePerMinifig': 0.0, 'PricePerPiece': 0.07935185185185185, 'YearsOnMarket': 5.0}\n",
      "Ejemplo de documento actualizado en lego_final_retirados: {'_id': ObjectId('67c8a69e30a1f61f23a23954'), 'PredictedInvestmentScore': None, 'PricePerMinifig': None, 'PricePerPiece': None, 'YearsOnMarket': None}\n",
      "Proceso completado con 茅xito. \n",
      "\n",
      "Validaci贸n Cruzada (5-fold):\n",
      "R虏 Medio: 0.9862, Desviaci贸n Est谩ndar: 0.0020\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "MONGO_DB = os.getenv(\"MONGO_DB\")\n",
    "\n",
    "# Conexi贸n a MongoDB\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[MONGO_DB]\n",
    "collection_venta = db[\"lego_final_venta\"]\n",
    "collection_retirados = db[\"lego_final_retirados\"]\n",
    "\n",
    "# Cargar datos desde MongoDB\n",
    "df_lego_venta = pd.DataFrame(list(collection_venta.find()))\n",
    "df_lego_retirados = pd.DataFrame(list(collection_retirados.find()))\n",
    "\n",
    "# Eliminar el campo '_id' si existe\n",
    "#df_lego_venta.drop(columns=['_id'], errors='ignore', inplace=True)\n",
    "#df_lego_retirados.drop(columns=['_id'], errors='ignore', inplace=True)\n",
    "\n",
    "# Eliminamos los sets promocionales con precio 0\n",
    "df_lego_retirados = df_lego_retirados[df_lego_retirados['USRetailPrice'] > 0]\n",
    "df_lego_venta = df_lego_venta[df_lego_venta['USRetailPrice'] > 0]\n",
    "\n",
    "# Codificamos la columna Exclusivity\n",
    "exclusivity_mapping = {'Regular': 0, 'Exclusive': 1}\n",
    "df_lego_retirados['Exclusivity'] = df_lego_retirados['Exclusivity'].map(exclusivity_mapping)\n",
    "df_lego_venta['Exclusivity'] = df_lego_venta['Exclusivity'].map(exclusivity_mapping)\n",
    "\n",
    "# Codificamos la columna SizeCategory\n",
    "size_category_mapping = {'Small': 0, 'Medium': 1, 'Large': 2}\n",
    "df_lego_retirados['SizeCategory'] = df_lego_retirados['SizeCategory'].map(size_category_mapping)\n",
    "df_lego_venta['SizeCategory'] = df_lego_venta['SizeCategory'].map(size_category_mapping)\n",
    "\n",
    "# Feature Engineering\n",
    "df_lego_retirados[\"PricePerPiece\"] = df_lego_retirados[\"USRetailPrice\"] / df_lego_retirados[\"Pieces\"]\n",
    "df_lego_venta[\"PricePerPiece\"] = df_lego_venta[\"USRetailPrice\"] / df_lego_venta[\"Pieces\"]\n",
    "\n",
    "df_lego_retirados[\"PricePerMinifig\"] = np.where(df_lego_retirados[\"Minifigs\"] > 0, df_lego_retirados[\"USRetailPrice\"] / df_lego_retirados[\"Minifigs\"], 0)\n",
    "df_lego_venta[\"PricePerMinifig\"] = np.where(df_lego_venta[\"Minifigs\"] > 0, df_lego_venta[\"USRetailPrice\"] / df_lego_venta[\"Minifigs\"], 0)\n",
    "\n",
    "df_lego_retirados[\"YearsOnMarket\"] = df_lego_retirados[\"ExitYear\"] - df_lego_retirados[\"LaunchYear\"]\n",
    "df_lego_venta[\"YearsOnMarket\"] = df_lego_venta[\"ExitYear\"] - df_lego_venta[\"LaunchYear\"]\n",
    "\n",
    "# Reemplazamos valores infinitos por NaN y rellenamos con la mediana en columnas num茅ricas\n",
    "for df in [df_lego_retirados, df_lego_venta]:\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Definimos variables\n",
    "features = ['USRetailPrice', 'Pieces', 'Minifigs', 'YearsSinceExit', 'ResaleDemand',\n",
    "            'AnnualPriceIncrease', 'Exclusivity', 'SizeCategory', 'PricePerPiece', 'PricePerMinifig', 'YearsOnMarket']\n",
    "target = 'InvestmentScore'\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X = df_lego_retirados[features]\n",
    "y = df_lego_retirados[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definimos los hiperpar谩metros para GridSearch\n",
    "rf_params = {'n_estimators': [50, 100, 150], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10]}\n",
    "hgb_params = {'learning_rate': [0.01, 0.1, 0.2], 'max_iter': [100, 200, 300], 'max_depth': [10, 20, None]}\n",
    "\n",
    "# GridSearch para Random Forest\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=5, n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# GridSearch para HistGradientBoosting\n",
    "hgb_grid = GridSearchCV(HistGradientBoostingRegressor(random_state=42), hgb_params, cv=5, n_jobs=-1, verbose=1)\n",
    "hgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos mejores hiperpar谩metros\n",
    "best_rf_params = rf_grid.best_params_\n",
    "best_hgb_params = hgb_grid.best_params_\n",
    "\n",
    "# Definimos los modelos optimizados\n",
    "rf_best = RandomForestRegressor(**best_rf_params, random_state=42)\n",
    "hgb_best = HistGradientBoostingRegressor(**best_hgb_params, random_state=42)\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Definimos modelo de Stacking\n",
    "base_models_optimized = [('rf', rf_best), ('hgb', hgb_best), ('lr', lr_model)]\n",
    "stacking_model_optimized = StackingRegressor(estimators=base_models_optimized, final_estimator=LinearRegression())\n",
    "\n",
    "# Validaci贸n cruzada\n",
    "cv_scores = cross_val_score(stacking_model_optimized, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Entrenamos el modelo optimizado\n",
    "stacking_model_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Aplicamos el modelo a los sets en venta\n",
    "df_lego_venta[\"PredictedInvestmentScore\"] = stacking_model_optimized.predict(df_lego_venta[features])\n",
    "\n",
    "# Ordenamos por mayor potencial de inversi贸n\n",
    "#df_lego_venta_sorted = df_lego_venta.sort_values(by=\"PredictedInvestmentScore\", ascending=False)\n",
    "\n",
    "# ===========================\n",
    "# **Actualizar MongoDB con nuevas columnas en ambas colecciones**\n",
    "# ===========================\n",
    "\n",
    "# Definir las columnas que queremos eliminar antes de actualizar\n",
    "columns_to_remove = [\"PricePerPiece\", \"PricePerMinifig\", \"YearsOnMarket\", \"PredictedInvestmentScore\"]\n",
    "\n",
    "# Paso 1: Eliminar las columnas antiguas en ambas colecciones si existen\n",
    "collection_venta.update_many({}, {\"$unset\": {col: \"\" for col in columns_to_remove}})\n",
    "collection_retirados.update_many({}, {\"$unset\": {col: \"\" for col in columns_to_remove}})\n",
    "\n",
    "# Funci贸n para agregar nuevas columnas si no existen y luego actualizar los datos\n",
    "def actualizar_mongodb(df, collection):\n",
    "    # Verificamos si la columna existe en la colecci贸n\n",
    "    existing_fields = collection.find_one()\n",
    "    fields_to_add = {col: None for col in columns_to_remove if col not in existing_fields}\n",
    "\n",
    "    # Si hay columnas que no existen, agregarlas\n",
    "    if fields_to_add:\n",
    "        collection.update_many({}, {\"$set\": fields_to_add})\n",
    "        print(f\"Columnas nuevas agregadas a la colecci贸n: {collection.name}\")\n",
    "\n",
    "    # Ahora, actualizamos los datos con los valores calculados\n",
    "    updates = []\n",
    "    for _, row in df.iterrows():\n",
    "        filter_query = {\"_id\": row[\"_id\"]}  # Asegurar que actualizamos el documento correcto\n",
    "        update_query = {\n",
    "            \"$set\": {\n",
    "                \"PricePerPiece\": row[\"PricePerPiece\"],\n",
    "                \"PricePerMinifig\": row[\"PricePerMinifig\"],\n",
    "                \"YearsOnMarket\": row[\"YearsOnMarket\"],\n",
    "                \"PredictedInvestmentScore\": row.get(\"PredictedInvestmentScore\", None)  # Si no existe, pone None\n",
    "            }\n",
    "        }\n",
    "        updates.append(UpdateOne(filter_query, update_query))\n",
    "\n",
    "    # Ejecutar las actualizaciones en MongoDB\n",
    "    if updates:\n",
    "        collection.bulk_write(updates)\n",
    "    print(f\"Datos actualizados correctamente en la colecci贸n: {collection.name}\")\n",
    "\n",
    "# Aplicamos la actualizaci贸n a ambas colecciones\n",
    "actualizar_mongodb(df_lego_venta, collection_venta)\n",
    "actualizar_mongodb(df_lego_retirados, collection_retirados)\n",
    "\n",
    "# Verificar si las actualizaciones se guardaron en MongoDB\n",
    "doc_venta = collection_venta.find_one({}, {\"PricePerPiece\": 1, \"PricePerMinifig\": 1, \"YearsOnMarket\": 1, \"PredictedInvestmentScore\": 1})\n",
    "doc_retirados = collection_retirados.find_one({}, {\"PricePerPiece\": 1, \"PricePerMinifig\": 1, \"YearsOnMarket\": 1, \"PredictedInvestmentScore\": 1})\n",
    "\n",
    "if doc_venta:\n",
    "    print(\"Ejemplo de documento actualizado en lego_final_venta:\", doc_venta)\n",
    "else:\n",
    "    print(\"No se encontraron documentos con las nuevas columnas en lego_final_venta.\")\n",
    "\n",
    "if doc_retirados:\n",
    "    print(\"Ejemplo de documento actualizado en lego_final_retirados:\", doc_retirados)\n",
    "else:\n",
    "    print(\"No se encontraron documentos con las nuevas columnas en lego_final_retirados.\")\n",
    "\n",
    "print(\"Proceso completado con 茅xito. \")\n",
    "\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(stacking_model_optimized, \"../05_Streamlit/models/stacking_model.pkl\", protocol=4, compress=3)\n",
    "\n",
    "print(\"\\nValidaci贸n Cruzada (5-fold):\")\n",
    "print(f\"R虏 Medio: {cv_scores.mean():.4f}, Desviaci贸n Est谩ndar: {cv_scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
